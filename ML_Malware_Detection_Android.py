import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# Import ML algorithms
from sklearn.model_selection import train_test_split  # import thing that will split the array into train/test subsets
from sklearn.metrics import confusion_matrix  # Allows us to measure performance: gives true/false positives/negatives
from sklearn.preprocessing import StandardScaler  # Scale the features to be b/w 0 and 1 to standardize them
from sklearn.neural_network import MLPClassifier  # A multi-layer perceptron neural network
from sklearn.ensemble import RandomForestClassifier  # Random forests, best classical ML approach to take

# Make a class called apkFile, to store apk files

class apkFile:
    # Constructor for apk class
    def __init__(self, filename):
        self.apkfile = apk.APK(self, filename)  # make an object, called apkfile, of the APK class from the apk library
        self.cert = apkfile.get_certificate  # google certification
        self.permissions = apkfile.get_permissions  # file permissions
        self.providers = apkfile.get_providers
        self.activities = apkfile.get_activities
        self.services = apkfile.get_services
        self.receivers = apkfile.get_receivers
        # self.cert_md5 : get md5 hash, see if its helpful ??
    # function that constructs a dictionary entry for an object (individual apk file)

    def construct(self):
        sample = {}
        for attr, k in self.__dict__.items():  # GO OVER THIS CODE W CLINTON
            if attr != "apk":
                sample[attr] = k
        return sample

"""apk2vec
 loops through all samples in a folder and extracts them, turns this collection of samples
 into a dataset
"""


def apk2vec(directory):
    dataset = {}
    for subdir, dirs, files in os.walk(directory):
        for f in files:
            file_path = os.path.join(subdir, f)
            try:
                apk = apkFile(file_path)
                dataset[str(f)] = apk.Construct()
            except Exception as e:
                print(e)
    return dataset

"""vec2csv
 Stores all samples in 1 csv file

"""


def vec2csv(dataset, filename):
    df = pd.DataFrame(dataset)
    df = df.transpose()  # transpose to have the features as columns and samples as rows
    df.to_csv(filename, sep=',', encoding='utf-8')  # ASK CLINTON

# The code that calls the functions and makes the two files
directoryPath_Malicious = 'C:\\apkCLEAN'  # the directory to index, with mal files
directoryPath_Clean = 'C:\\apkCLEAN'  # the clean directory to index

dataset_Malicious = apk2vec(directoryPath_Malicious)
dataset_Clean = apk2vec(directoryPath_Clean)

vec2csv(dataset_Malicious, 'dataset_Malicious.csv')
vec2csv(dataset_Clean, 'dataset_Clean.csv')

malicious = pd.read_csv("dataset_Malicious.csv")
clean = pd.read_csv("dataset_Clean.csv")

dataset_Merged = [malicious, clean]
dataset = pd.concat(dataset_Merged)
vec2csv(dataset.transpose(), 'dataset_Merged.csv')

# Visualize data using stats - TO BE ADDED

# Visualize data using matplotlib - TO BE ADDED

# Dataset prep, algorithm implementation

state = np.random.randint(100)
y = dataset['clean']
X = dataset.drop('clean', axis=1)
X = np.asarray(X)
y = np.asarray(y)

X = X[:, 1:13]  # get rid of the zeroth column of X (the filename), and the last column (the file path) -P
print(X[1, 11])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)

# Random Forests
classifier1 = RandomForestClassifier()
classifier2.fit(X_train, y_train)
y_pred = classifier1.predict(X_test)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
print("TN = ", tn)
print("TP = ", tp)
print("FP = ", fp)
print("FN = ", fn)

# MLP
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

mlp = MLPClassifier(hidden_layer_sizes=(12, 12, 12, 12, 12, 12))
mlp.fit(X_train, y_train)
predictions = mlp.predict(X_test)

tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()
print("TN = ", tn)
print("TP = ", tp)
print("FP = ", fp)
print("FN = ", fn)
